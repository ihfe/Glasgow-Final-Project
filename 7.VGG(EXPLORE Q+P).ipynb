{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyMkWVrmSQy7YVs9pkoPXw86"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["ğŸ“Œä»`torchvision.datasets`ä¸­åŠ è½½æ•°æ®é›†"],"metadata":{"id":"PohmHjgdSTFX"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import time\n","import copy\n","import torch.ao.quantization.quantize_fx as quantize_fx\n","import os\n","from torch.ao.quantization import (\n","  get_default_qconfig_mapping,\n","  get_default_qat_qconfig_mapping,\n","  QConfigMapping,\n",")"],"metadata":{"id":"KIodakDZtiP0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------- 1. æ¨¡å‹å®šä¹‰ ----------\n","# VGG11 é…ç½®\n","vgg11_cfg = [64, 'M', 128, 'M', 256, 'M', 512, 'M', 512, 'M']\n","\n","class VGG11(nn.Module):\n","    def __init__(self):\n","        super(VGG11, self).__init__()\n","        self.features = self._make_layers(vgg11_cfg)\n","        self.classifier = nn.Linear(512, 10)  # CIFAR-10 has 10 classes\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        return out\n","\n","    def _make_layers(self, cfg):\n","        layers = []\n","        in_channels = 3\n","        for x in cfg:\n","            if x == 'M':\n","                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","            else:\n","                layers += [\n","                    nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(x),\n","                    nn.ReLU(inplace=True)\n","                ]\n","                in_channels = x\n","        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n","        return nn.Sequential(*layers)"],"metadata":{"collapsed":true,"id":"aJuq8BAvRKer"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# ç”¨äºæµ‹è¯•æ¨¡å‹ç²¾åº¦ä»¥åŠé€Ÿåº¦çš„å‡½æ•°\n","def test(model, test_loader, debug = False):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        start_time = time.time()\n","        for data in test_loader:\n","            images, labels = data\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        end_time = time.time()\n","    accuracy = 100 * correct / total\n","    time_cost = end_time - start_time\n","    if debug:\n","        print('Accuracy of the network on the %d test images: %.2f %%' % (n_test, accuracy))\n","        print('Time cost: %.2f s' % time_cost)\n","    return accuracy, time_cost\n","\n","# ç”¨äºè·å–æ¨¡å‹å¤§å°çš„å‡½æ•°ï¼Œå•ä½ä¸º MB\n","def get_model_size(model):\n","    torch.save(model.state_dict(), \"temp.pth\")\n","    size = os.path.getsize(\"temp.pth\")/1e6\n","    os.remove('temp.pth')\n","    return size"],"metadata":{"id":"U9yE-n5T_-Mq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754824942979,"user_tz":-60,"elapsed":73801,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"88460c52-72ec-4f88-f615-8354888be526"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# åŠ è½½ CIFAR10 æ•°æ®é›†\n","batch_size = 64\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='/bohr/cifar10-h7hf/v2', train=True, download=True, transform=transform_train)\n","train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","\n","testset = torchvision.datasets.CIFAR10(root='/bohr/cifar10-h7hf/v2', train=False, download=True, transform=transform_test)\n","test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n","n_test = len(testset)\n","example_input = (testset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QI40205FtWTl","executionInfo":{"status":"ok","timestamp":1754824952249,"user_tz":-60,"elapsed":7661,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"22663084-c71c-47a1-b0a9-dbe923014751"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:03<00:00, 43.7MB/s]\n"]}]},{"cell_type":"code","source":["# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹\n","model_fp = VGG11()\n","model_fp.load_state_dict(torch.load('/content/drive/MyDrive/ç¬¬äºŒæ¬¡å°è¯•/VGG11_CIFAR10.pth', map_location=torch.device('cpu')))"],"metadata":{"id":"-dOi_3nFM9zH","executionInfo":{"status":"ok","timestamp":1754824954537,"user_tz":-60,"elapsed":2284,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5dba98c7-8534-458a-d49d-7a2bfbb65767"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["model_to_quantize_ptsq = copy.deepcopy(model_fp)\n","model_to_quantize_ptsq.eval()\n","\n","qconfig_mapping = get_default_qconfig_mapping(\"qnnpack\")\n","model_prepared_ptsq = quantize_fx.prepare_fx(model_to_quantize_ptsq, qconfig_mapping, example_input)\n","# è¿™é‡Œä½¿ç”¨å…¨éƒ¨çš„è®­ç»ƒæ•°æ®æ¥å¯¹æ¨¡å‹è¿›è¡Œæ ¡å‡†\n","# æ³¨æ„ï¼šæ ¡å‡†å¹¶ä¸æ˜¯è®­ç»ƒï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦å¯¹æ¨¡å‹åšåå‘ä¼ æ’­\n","model_prepared_ptsq.eval()\n","with torch.no_grad():\n","    for images, labels in train_loader:\n","        model_prepared_ptsq(images)\n","\n","model_quantized_ptsq = quantize_fx.convert_fx(model_prepared_ptsq)"],"metadata":{"id":"vfMpdkL4tPYh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["é‡åŒ–ç»“æŸï¼Œæˆ‘ä»¬å¼€å§‹å¯¹`model_quantized_ptsq`æ¨¡å‹çš„å·ç§¯å±‚è¿›è¡Œå‰ªæï¼š\n","1.æ‰¾åˆ°æ¨¡å‹çš„å·ç§¯å±‚æœ‰å“ªäº›\n","2.ä½¿ç”¨å°è£…å¥½çš„æ–¹æ³•å¾—åˆ°æ¨¡å‹å·ç§¯å±‚æ•æ„Ÿåº¦\n","3."],"metadata":{"id":"2toaZHsKuc_4"}},{"cell_type":"code","source":[],"metadata":{"id":"0iIktrtmtSEG"},"execution_count":null,"outputs":[]}]}