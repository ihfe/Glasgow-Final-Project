{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "collapsed_sections": [
        "OjRQ0sbWA2WC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### üìå 1.Load model and Dataset"
      ],
      "metadata": {
        "id": "pD6rhQx3nyf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from copy import deepcopy\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.utils.prune as prune\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "model = models.vgg11(pretrained=False)\n",
        "model.classifier[6] = nn.Linear(4096, 10)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Á¨¨‰∫åÊ¨°Â∞ùËØï/VGG11_C10_layer_sensitivity.pth\", map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t33Z2iYJlxA5",
        "outputId": "88912174-111b-492c-8c95-4aa27724d21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºàVGG ‰ΩøÁî® ImageNet È¢ÑËÆ≠ÁªÉÔºåÂõ†Ê≠§ÈúÄÂΩí‰∏ÄÂåñÂà∞ ImageNet ÂùáÂÄºÔºâ\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Âä†ËΩΩ CIFAR-10 Êï∞ÊçÆÈõÜ\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "QJMhh_Lwl1wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÂáÜÁ°ÆÁéáËØÑ‰º∞ÂáΩÊï∞\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "COOsX-B-lw2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3euNMIOQn6cZ",
        "outputId": "b99259b5-9e31-4166-e4e5-90afb39faea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. üìåStart Unstructured prune"
      ],
      "metadata": {
        "id": "FUb_CfRfn4t1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.1„ÄÅIternative prune:"
      ],
      "metadata": {
        "id": "hyIL3HarJbuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layers = [(name, m) for name, m in model.features.named_modules() if isinstance(m, nn.Conv2d)]\n",
        "layer_names = [name for name, _ in conv_layers]\n",
        "conv_layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBPTArdklwvS",
        "outputId": "3b85580b-d3ab-4444-d3b4-0e26a6b4571b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0', Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              " ('3', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              " ('6', Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              " ('8', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              " ('11', Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              " ('13', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              " ('16', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              " ('18', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilize the layer sensitivity we get before\n",
        "prune_rate = [0.1,0.4,0.5,0.5,0.6,0.6,0.5,0.7]"
      ],
      "metadata": {
        "id": "PgOScOFClwn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (name, layer), amt in zip(conv_layers, prune_rate):\n",
        "    prune.l1_unstructured(layer, name='weight', amount=amt)\n",
        "    prune.remove(layer,\"weight\")"
      ],
      "metadata": {
        "id": "j2235gmWlwhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Sparity After Iterative pruning\n",
        "def calculate_model_sparsity(model):\n",
        "    total_params = 0\n",
        "    zero_params = 0\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"weight\" in name and param.requires_grad:\n",
        "            num_params = param.numel()\n",
        "            num_zeros = torch.sum(param == 0).item()\n",
        "            total_params += num_params\n",
        "            zero_params += num_zeros\n",
        "            layer_sparsity = 100.0 * num_zeros / num_params\n",
        "            print(f\"{name:40} | Sparsity: {layer_sparsity:.2f}% ({num_zeros}/{num_params})\")\n",
        "\n",
        "    total_sparsity = 100.0 * zero_params / total_params\n",
        "    print(f\"\\nüîç Total model sparsity: {total_sparsity:.2f}% ({zero_params}/{total_params})\")\n",
        "\n",
        "    return total_sparsity\n",
        "# get the sparity\n",
        "sparsity = calculate_model_sparsity(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reF40czVlwGF",
        "outputId": "76b74dd1-2163-45d9-faa0-a70a35dd01ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.0.weight                        | Sparsity: 10.01% (173/1728)\n",
            "features.3.weight                        | Sparsity: 40.00% (29491/73728)\n",
            "features.6.weight                        | Sparsity: 50.00% (147456/294912)\n",
            "features.8.weight                        | Sparsity: 50.00% (294912/589824)\n",
            "features.11.weight                       | Sparsity: 60.00% (707789/1179648)\n",
            "features.13.weight                       | Sparsity: 60.00% (1415578/2359296)\n",
            "features.16.weight                       | Sparsity: 50.00% (1179648/2359296)\n",
            "features.18.weight                       | Sparsity: 70.00% (1651507/2359296)\n",
            "classifier.0.weight                      | Sparsity: 0.00% (0/102760448)\n",
            "classifier.3.weight                      | Sparsity: 0.00% (0/16777216)\n",
            "classifier.6.weight                      | Sparsity: 0.00% (0/40960)\n",
            "\n",
            "üîç Total model sparsity: 4.21% (5426554/128796352)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOfpZ5rblv9w",
        "outputId": "ca2eb102-af78-4ebe-cb4a-dda2a38cd877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.2„ÄÅGlobal pruning:\n",
        "- Each layer's Sensitivity is [0.1,0.4,0.5,0.5,0.6,0.6,0.5,0.7], when we do Global pruning, we directly select 0.7 as global prune"
      ],
      "metadata": {
        "id": "WSaktlmjJf4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÈÄâÊã©ÂèÇ‰∏éÂâ™ÊûùÁöÑÊ®°ÂùóÁ±ªÂûãÔºàÈÄöÂ∏∏ÊòØ Conv2d Âíå LinearÔºâ\n",
        "modules_to_prune = []\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "        modules_to_prune.append((module, 'weight'))  # Ââ™ÊûùÂèÇÊï∞ÈÄöÂ∏∏ÊòØ weight\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4zMXSYpzJTKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prune.global_unstructured(\n",
        "    modules_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,  # ÂèØÈÄâ L1Unstructured Êàñ RandomUnstructured\n",
        "    amount=0.7  # ÂÖ®Â±ÄÂâ™Êûù 70% ÁöÑÂèÇÊï∞\n",
        ")"
      ],
      "metadata": {
        "id": "NyjiFC1yKFMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for module, name in modules_to_prune:\n",
        "    prune.remove(module, name)"
      ],
      "metadata": {
        "id": "YI0NAEeEK-Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Sparity After global pruning\n",
        "def calculate_model_sparsity(model):\n",
        "    total_params = 0\n",
        "    zero_params = 0\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"weight\" in name and param.requires_grad:\n",
        "            num_params = param.numel()\n",
        "            num_zeros = torch.sum(param == 0).item()\n",
        "            total_params += num_params\n",
        "            zero_params += num_zeros\n",
        "            layer_sparsity = 100.0 * num_zeros / num_params\n",
        "            print(f\"{name:40} | Sparsity: {layer_sparsity:.2f}% ({num_zeros}/{num_params})\")\n",
        "\n",
        "    total_sparsity = 100.0 * zero_params / total_params\n",
        "    print(f\"\\nüîç Total model sparsity: {total_sparsity:.2f}% ({zero_params}/{total_params})\")\n",
        "\n",
        "    return total_sparsity\n",
        "# get the sparity\n",
        "sparsity = calculate_model_sparsity(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JpBYPX-KFmg",
        "outputId": "228450b6-106a-434c-c3d6-fdff71154510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.0.weight                        | Sparsity: 2.43% (42/1728)\n",
            "features.3.weight                        | Sparsity: 17.81% (13131/73728)\n",
            "features.6.weight                        | Sparsity: 23.00% (67842/294912)\n",
            "features.8.weight                        | Sparsity: 26.26% (154869/589824)\n",
            "features.11.weight                       | Sparsity: 30.03% (354247/1179648)\n",
            "features.13.weight                       | Sparsity: 35.53% (838221/2359296)\n",
            "features.16.weight                       | Sparsity: 34.36% (810612/2359296)\n",
            "features.18.weight                       | Sparsity: 35.60% (839893/2359296)\n",
            "classifier.0.weight                      | Sparsity: 75.67% (77754423/102760448)\n",
            "classifier.3.weight                      | Sparsity: 55.45% (9302496/16777216)\n",
            "classifier.6.weight                      | Sparsity: 52.91% (21670/40960)\n",
            "\n",
            "üîç Total model sparsity: 70.00% (90157446/128796352)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuavt97wKFtX",
        "outputId": "0afd4aad-2965-4b98-82f6-9a66eae79483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.3 Fine-tunning"
      ],
      "metadata": {
        "id": "dLWcFESkyCTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fine tuning Iternative prune model\n",
        "model_finetunning = deepcopy(model)\n",
        "model_finetunning = model_finetunning.to(device)\n",
        "\n",
        "# ÂèØÈÄâÔºöÂÜªÁªìÁâπÂæÅÊèêÂèñÈÉ®ÂàÜ\n",
        "for param in model_finetunning.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -----------------------\n",
        "# 3. ÂÆö‰πâÊçüÂ§±Âíå‰ºòÂåñÂô®\n",
        "# -----------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_finetunning.parameters(), lr=0.0001)\n",
        "\n",
        "# -----------------------\n",
        "# 4. Ê®°ÂûãËÆ≠ÁªÉ\n",
        "# -----------------------\n",
        "for epoch in range(5):  # ÂèØÊ†πÊçÆÈúÄË¶ÅÊîπepochÊï∞\n",
        "    model_finetunning.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_finetunning(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # ÊØè100‰∏™mini-batchÊâìÂç∞‰∏ÄÊ¨°loss\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss/100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I9PQLXxflv0o",
        "outputId": "c01a8940-833f-4125-c8ec-39103a2c2283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 100] loss: 0.069\n",
            "[Epoch 1, Batch 200] loss: 0.062\n",
            "[Epoch 1, Batch 300] loss: 0.072\n",
            "[Epoch 1, Batch 400] loss: 0.073\n",
            "[Epoch 1, Batch 500] loss: 0.067\n",
            "[Epoch 1, Batch 600] loss: 0.080\n",
            "[Epoch 1, Batch 700] loss: 0.071\n",
            "[Epoch 2, Batch 100] loss: 0.040\n",
            "[Epoch 2, Batch 200] loss: 0.039\n",
            "[Epoch 2, Batch 300] loss: 0.041\n",
            "[Epoch 2, Batch 400] loss: 0.045\n",
            "[Epoch 2, Batch 500] loss: 0.055\n",
            "[Epoch 2, Batch 600] loss: 0.042\n",
            "[Epoch 2, Batch 700] loss: 0.049\n",
            "[Epoch 3, Batch 100] loss: 0.027\n",
            "[Epoch 3, Batch 200] loss: 0.026\n",
            "[Epoch 3, Batch 300] loss: 0.032\n",
            "[Epoch 3, Batch 400] loss: 0.033\n",
            "[Epoch 3, Batch 500] loss: 0.031\n",
            "[Epoch 3, Batch 600] loss: 0.030\n",
            "[Epoch 3, Batch 700] loss: 0.038\n",
            "[Epoch 4, Batch 100] loss: 0.030\n",
            "[Epoch 4, Batch 200] loss: 0.024\n",
            "[Epoch 4, Batch 300] loss: 0.032\n",
            "[Epoch 4, Batch 400] loss: 0.025\n",
            "[Epoch 4, Batch 500] loss: 0.035\n",
            "[Epoch 4, Batch 600] loss: 0.038\n",
            "[Epoch 4, Batch 700] loss: 0.025\n",
            "[Epoch 5, Batch 100] loss: 0.016\n",
            "[Epoch 5, Batch 200] loss: 0.016\n",
            "[Epoch 5, Batch 300] loss: 0.013\n",
            "[Epoch 5, Batch 400] loss: 0.021\n",
            "[Epoch 5, Batch 500] loss: 0.020\n",
            "[Epoch 5, Batch 600] loss: 0.017\n",
            "[Epoch 5, Batch 700] loss: 0.027\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Re-evaluate\n",
        "print(evaluate(model_finetunning))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZm8V_uiwa1W",
        "outputId": "8e384ebb-ef0e-4f2b-d1dd-9f0ba9b92e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5919132/128796352"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEHMqXWRRalD",
        "outputId": "725166ca-7fa2-4a1b-8882-0a7417705413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.045957295436442176"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate Sparsity\n",
        "sparsity = calculate_model_sparsity(model_finetunning)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUzzdvpcwbLy",
        "outputId": "8ab4994c-34a9-4349-ce4f-72fc757dfb55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.0.weight                        | Sparsity: 10.01% (173/1728)\n",
            "features.3.weight                        | Sparsity: 40.00% (29491/73728)\n",
            "features.6.weight                        | Sparsity: 50.00% (147456/294912)\n",
            "features.8.weight                        | Sparsity: 50.00% (294912/589824)\n",
            "features.11.weight                       | Sparsity: 60.00% (707789/1179648)\n",
            "features.13.weight                       | Sparsity: 60.00% (1415578/2359296)\n",
            "features.16.weight                       | Sparsity: 50.00% (1179648/2359296)\n",
            "features.18.weight                       | Sparsity: 70.00% (1651507/2359296)\n",
            "classifier.0.weight                      | Sparsity: 0.00% (0/102760448)\n",
            "classifier.3.weight                      | Sparsity: 0.00% (0/16777216)\n",
            "classifier.6.weight                      | Sparsity: 0.00% (0/40960)\n",
            "\n",
            "üîç Total model sparsity: 4.21% (5426554/128796352)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####  Fine-tunning global prune model\n",
        "model_finetunning = deepcopy(model)\n",
        "model_finetunning = model_finetunning.to(device)\n",
        "\n",
        "# ÂèØÈÄâÔºöÂÜªÁªìÁâπÂæÅÊèêÂèñÈÉ®ÂàÜ\n",
        "for param in model_finetunning.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -----------------------\n",
        "# 3. ÂÆö‰πâÊçüÂ§±Âíå‰ºòÂåñÂô®\n",
        "# -----------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_finetunning.parameters(), lr=0.0001)\n",
        "\n",
        "# -----------------------\n",
        "# 4. Ê®°ÂûãËÆ≠ÁªÉ\n",
        "# -----------------------\n",
        "for epoch in range(5):  # ÂèØÊ†πÊçÆÈúÄË¶ÅÊîπepochÊï∞\n",
        "    model_finetunning.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_finetunning(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # ÊØè100‰∏™mini-batchÊâìÂç∞‰∏ÄÊ¨°loss\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss/100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Eks2KpL0OH8R",
        "outputId": "eda50d39-2b12-4c46-b647-d2eb547bc841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 100] loss: 0.054\n",
            "[Epoch 1, Batch 200] loss: 0.047\n",
            "[Epoch 1, Batch 300] loss: 0.045\n",
            "[Epoch 1, Batch 400] loss: 0.047\n",
            "[Epoch 1, Batch 500] loss: 0.045\n",
            "[Epoch 1, Batch 600] loss: 0.052\n",
            "[Epoch 1, Batch 700] loss: 0.055\n",
            "[Epoch 2, Batch 100] loss: 0.023\n",
            "[Epoch 2, Batch 200] loss: 0.027\n",
            "[Epoch 2, Batch 300] loss: 0.035\n",
            "[Epoch 2, Batch 400] loss: 0.026\n",
            "[Epoch 2, Batch 500] loss: 0.031\n",
            "[Epoch 2, Batch 600] loss: 0.035\n",
            "[Epoch 2, Batch 700] loss: 0.027\n",
            "[Epoch 3, Batch 100] loss: 0.017\n",
            "[Epoch 3, Batch 200] loss: 0.021\n",
            "[Epoch 3, Batch 300] loss: 0.020\n",
            "[Epoch 3, Batch 400] loss: 0.024\n",
            "[Epoch 3, Batch 500] loss: 0.026\n",
            "[Epoch 3, Batch 600] loss: 0.023\n",
            "[Epoch 3, Batch 700] loss: 0.029\n",
            "[Epoch 4, Batch 100] loss: 0.012\n",
            "[Epoch 4, Batch 200] loss: 0.015\n",
            "[Epoch 4, Batch 300] loss: 0.012\n",
            "[Epoch 4, Batch 400] loss: 0.018\n",
            "[Epoch 4, Batch 500] loss: 0.014\n",
            "[Epoch 4, Batch 600] loss: 0.022\n",
            "[Epoch 4, Batch 700] loss: 0.017\n",
            "[Epoch 5, Batch 100] loss: 0.009\n",
            "[Epoch 5, Batch 200] loss: 0.006\n",
            "[Epoch 5, Batch 300] loss: 0.014\n",
            "[Epoch 5, Batch 400] loss: 0.011\n",
            "[Epoch 5, Batch 500] loss: 0.011\n",
            "[Epoch 5, Batch 600] loss: 0.016\n",
            "[Epoch 5, Batch 700] loss: 0.015\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the result is after gloabal pruning and fine-tunning\n",
        "print(evaluate(model_finetunning))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCzYUpa9OfbZ",
        "outputId": "6823eff8-dc84-4939-e5a7-0e8bf85ec698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate Sparsity\n",
        "sparsity = calculate_model_sparsity(model_finetunning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWDqk3UXOhqs",
        "outputId": "18aadab5-27e5-475d-8003-bd772df243ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.0.weight                      | Sparsity: 0.36% (374966/102760448)\n",
            "classifier.3.weight                      | Sparsity: 0.70% (117577/16777216)\n",
            "classifier.6.weight                      | Sparsity: 0.09% (35/40960)\n",
            "\n",
            "üîç Total model sparsity: 0.41% (492578/119578624)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. üìåStart Structured prune"
      ],
      "metadata": {
        "id": "IoURe6C5xSRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg11(pretrained=False)\n",
        "model.classifier[6] = nn.Linear(4096, 10)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Á¨¨‰∫åÊ¨°Â∞ùËØï/VGG11_C10_layer_sensitivity.pth\", map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYzIztjw0Mk3",
        "outputId": "bac7902b-5d1b-4ee5-ac85-a5bf8ef87057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prune_rates = [0.1, 0.4, 0.5, 0.5, 0.6, 0.6, 0.5, 0.7]\n",
        "conv_idx = 0\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        rate = prune_rates[conv_idx]\n",
        "        prune.ln_structured(module, name='weight', amount=rate, n=2, dim=0)\n",
        "        prune.remove(module, 'weight')\n",
        "        print(f\"Pruned {name} with rate {rate}\")\n",
        "        conv_idx += 1\n",
        "        if conv_idx >= len(prune_rates):\n",
        "            break  # ÈÅøÂÖç‰∏ãÊ†áË∂äÁïå"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxLU_RqwwbdK",
        "outputId": "4b0b5d67-c547-4e34-e75a-d2a9c793e992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned features.0 with rate 0.1\n",
            "Pruned features.3 with rate 0.4\n",
            "Pruned features.6 with rate 0.5\n",
            "Pruned features.8 with rate 0.5\n",
            "Pruned features.11 with rate 0.6\n",
            "Pruned features.13 with rate 0.6\n",
            "Pruned features.16 with rate 0.5\n",
            "Pruned features.18 with rate 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqznWAu8wbh7",
        "outputId": "49c301b3-397d-4d7f-d29c-1273450c16c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_finetunning = deepcopy(model)\n",
        "model_finetunning = model_finetunning.to(device)\n",
        "\n",
        "# ÂèØÈÄâÔºöÂÜªÁªìÁâπÂæÅÊèêÂèñÈÉ®ÂàÜ\n",
        "for param in model_finetunning.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -----------------------\n",
        "# 3. ÂÆö‰πâÊçüÂ§±Âíå‰ºòÂåñÂô®\n",
        "# -----------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_finetunning.parameters(), lr=0.0001)\n",
        "\n",
        "# -----------------------\n",
        "# 4. Ê®°ÂûãËÆ≠ÁªÉ\n",
        "# -----------------------\n",
        "for epoch in range(3):  # ÂèØÊ†πÊçÆÈúÄË¶ÅÊîπepochÊï∞\n",
        "    model_finetunning.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_finetunning(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # ÊØè100‰∏™mini-batchÊâìÂç∞‰∏ÄÊ¨°loss\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss/100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Re-Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtIk_VGu2YPH",
        "outputId": "46b5e363-417c-4ea7-ed2a-2b7b05e37113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 100] loss: 2.647\n",
            "[Epoch 1, Batch 200] loss: 2.305\n",
            "[Epoch 1, Batch 300] loss: 2.301\n",
            "[Epoch 1, Batch 400] loss: 2.290\n",
            "[Epoch 1, Batch 500] loss: 2.269\n",
            "[Epoch 1, Batch 600] loss: 2.246\n",
            "[Epoch 1, Batch 700] loss: 2.249\n",
            "[Epoch 2, Batch 100] loss: 2.213\n",
            "[Epoch 2, Batch 200] loss: 2.212\n",
            "[Epoch 2, Batch 300] loss: 2.207\n",
            "[Epoch 2, Batch 400] loss: 2.207\n",
            "[Epoch 2, Batch 500] loss: 2.193\n",
            "[Epoch 2, Batch 600] loss: 2.187\n",
            "[Epoch 2, Batch 700] loss: 2.187\n",
            "[Epoch 3, Batch 100] loss: 2.176\n",
            "[Epoch 3, Batch 200] loss: 2.161\n",
            "[Epoch 3, Batch 300] loss: 2.153\n",
            "[Epoch 3, Batch 400] loss: 2.187\n",
            "[Epoch 3, Batch 500] loss: 2.174\n",
            "[Epoch 3, Batch 600] loss: 2.162\n",
            "[Epoch 3, Batch 700] loss: 2.160\n",
            "Finished Re-Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Á®ÄÁñèÂ∫¶ËÆ°ÁÆó\n",
        "def calculate_model_sparsity(model):\n",
        "    total_params = 0\n",
        "    zero_params = 0\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"weight\" in name:\n",
        "            num_params = param.numel()\n",
        "            num_zeros = torch.sum(param == 0).item()\n",
        "            total_params += num_params\n",
        "            zero_params += num_zeros\n",
        "            layer_sparsity = 100.0 * num_zeros / num_params\n",
        "            print(f\"{name:40} | Sparsity: {layer_sparsity:.2f}% ({num_zeros}/{num_params})\")\n",
        "\n",
        "    total_sparsity = 100.0 * zero_params / total_params\n",
        "    print(f\"\\nüîç Total model sparsity: {total_sparsity:.2f}% ({zero_params}/{total_params})\")\n",
        "\n",
        "    return total_sparsity\n",
        "# ÂÅáËÆæ‰Ω†Êúâ‰∏Ä‰∏™Ââ™ÊûùÂêéÁöÑÊ®°Âûã\n",
        "sparsity = calculate_model_sparsity(model_finetunning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQD-iUXewbms",
        "outputId": "c4b04ad2-ef50-4c1e-bced-520906f28824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.0.weight                        | Sparsity: 9.38% (162/1728)\n",
            "features.3.weight                        | Sparsity: 39.84% (29376/73728)\n",
            "features.6.weight                        | Sparsity: 50.00% (147456/294912)\n",
            "features.8.weight                        | Sparsity: 50.00% (294912/589824)\n",
            "features.11.weight                       | Sparsity: 59.96% (707328/1179648)\n",
            "features.13.weight                       | Sparsity: 59.96% (1414656/2359296)\n",
            "features.16.weight                       | Sparsity: 50.00% (1179648/2359296)\n",
            "features.18.weight                       | Sparsity: 69.92% (1649664/2359296)\n",
            "classifier.0.weight                      | Sparsity: 0.00% (0/102760448)\n",
            "classifier.3.weight                      | Sparsity: 0.00% (0/16777216)\n",
            "classifier.6.weight                      | Sparsity: 0.00% (0/40960)\n",
            "\n",
            "üîç Total model sparsity: 4.21% (5423202/128796352)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(model_finetunning))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3cFdXi52E7f",
        "outputId": "ef7b3b46-9fe2-499a-a831-7e952cdb10af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qpGzRvU_2FZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. üìåJust ignore the following code„Äêfor personal use„Äë"
      ],
      "metadata": {
        "id": "OjRQ0sbWA2WC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W24dxrVTwbqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "from copy import deepcopy\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pz8UcLgFEHVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºöresize Âíå normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),  # Âõ†‰∏∫ VGG ËæìÂÖ•ÊòØ 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Âä†ËΩΩËÆ≠ÁªÉÈõÜ\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "# Âä†ËΩΩÊµãËØïÈõÜ\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "DmHy67D5EHOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2380f48a-7a2d-42fa-e974-25cfc674a616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:13<00:00, 12.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ËÆæÁΩÆËÆæÂ§á\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUxY8dieOyEK",
        "outputId": "1b9e75a5-00bc-4e5b-c521-a233267f3382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 2. Âä†ËΩΩÂπ∂‰øÆÊîπÈ¢ÑËÆ≠ÁªÉÊ®°Âûã\n",
        "# -----------------------\n",
        "model = models.vgg11(pretrained=True)\n",
        "\n",
        "# ÊõøÊç¢ÊúÄÂêé‰∏ÄÂ±ÇÔºö1000 -> 10\n",
        "model.classifier[6] = nn.Linear(4096, 10)\n",
        "\n",
        "# Â∞ÜÊ®°ÂûãÊîæÂà∞ GPUÔºàÂ¶ÇÊúâÔºâ\n",
        "model = model.to(device)\n",
        "\n",
        "# ÂèØÈÄâÔºöÂÜªÁªìÁâπÂæÅÊèêÂèñÈÉ®ÂàÜ\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -----------------------\n",
        "# 3. ÂÆö‰πâÊçüÂ§±Âíå‰ºòÂåñÂô®\n",
        "# -----------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# -----------------------\n",
        "# 4. Ê®°ÂûãËÆ≠ÁªÉ\n",
        "# -----------------------\n",
        "for epoch in range(5):  # ÂèØÊ†πÊçÆÈúÄË¶ÅÊîπepochÊï∞\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # ÊØè100‰∏™mini-batchÊâìÂç∞‰∏ÄÊ¨°loss\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss/100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "reP3BJInEHJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "0dede7c4-8b74-4372-a213-be5498fae00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 100] loss: 1.010\n",
            "[Epoch 1, Batch 200] loss: 0.671\n",
            "[Epoch 1, Batch 300] loss: 0.580\n",
            "[Epoch 1, Batch 400] loss: 0.548\n",
            "[Epoch 1, Batch 500] loss: 0.485\n",
            "[Epoch 1, Batch 600] loss: 0.462\n",
            "[Epoch 1, Batch 700] loss: 0.463\n",
            "[Epoch 2, Batch 100] loss: 0.275\n",
            "[Epoch 2, Batch 200] loss: 0.254\n",
            "[Epoch 2, Batch 300] loss: 0.279\n",
            "[Epoch 2, Batch 400] loss: 0.256\n",
            "[Epoch 2, Batch 500] loss: 0.283\n",
            "[Epoch 2, Batch 600] loss: 0.274\n",
            "[Epoch 2, Batch 700] loss: 0.281\n",
            "[Epoch 3, Batch 100] loss: 0.138\n",
            "[Epoch 3, Batch 200] loss: 0.115\n",
            "[Epoch 3, Batch 300] loss: 0.126\n",
            "[Epoch 3, Batch 400] loss: 0.124\n",
            "[Epoch 3, Batch 500] loss: 0.122\n",
            "[Epoch 3, Batch 600] loss: 0.132\n",
            "[Epoch 3, Batch 700] loss: 0.134\n",
            "[Epoch 4, Batch 100] loss: 0.061\n",
            "[Epoch 4, Batch 200] loss: 0.061\n",
            "[Epoch 4, Batch 300] loss: 0.067\n",
            "[Epoch 4, Batch 400] loss: 0.076\n",
            "[Epoch 4, Batch 500] loss: 0.077\n",
            "[Epoch 4, Batch 600] loss: 0.080\n",
            "[Epoch 4, Batch 700] loss: 0.085\n",
            "[Epoch 5, Batch 100] loss: 0.047\n",
            "[Epoch 5, Batch 200] loss: 0.043\n",
            "[Epoch 5, Batch 300] loss: 0.046\n",
            "[Epoch 5, Batch 400] loss: 0.056\n",
            "[Epoch 5, Batch 500] loss: 0.058\n",
            "[Epoch 5, Batch 600] loss: 0.048\n",
            "[Epoch 5, Batch 700] loss: 0.056\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 5. Ê®°ÂûãÊµãËØï\n",
        "# -----------------------\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "X_EM5wixEHHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60f759a-31e1-4df5-9c8f-806e3d1a2e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 85.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÂáÜÁ°ÆÁéáËØÑ‰º∞ÂáΩÊï∞\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "print(evaluate(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yab5dhFIjAWK",
        "outputId": "39fa9a70-8911-479d-b2a5-9492a1d5d764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# ÂÆö‰πâ‰øùÂ≠òË∑ØÂæÑ\n",
        "save_path = \"/content/drive/MyDrive/Ê®°Âûã/VGG11_CIFAR.pth\"\n",
        "# ‰øùÂ≠òÊ®°ÂûãÂèÇÊï∞\n",
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "91Iqjm7MEHDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1d87a1-364d-49b7-88d0-43fdee71a63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HdUPTIgzEG90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 2. Âä†ËΩΩÂπ∂‰øÆÊîπÈ¢ÑËÆ≠ÁªÉÊ®°Âûã\n",
        "# -----------------------\n",
        "model = models.vgg13(pretrained=True)\n",
        "\n",
        "# ÊõøÊç¢ÊúÄÂêé‰∏ÄÂ±ÇÔºö1000 -> 10\n",
        "model.classifier[6] = nn.Linear(4096, 10)\n",
        "\n",
        "# Â∞ÜÊ®°ÂûãÊîæÂà∞ GPUÔºàÂ¶ÇÊúâÔºâ\n",
        "model = model.to(device)\n",
        "\n",
        "# ÂèØÈÄâÔºöÂÜªÁªìÁâπÂæÅÊèêÂèñÈÉ®ÂàÜ\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -----------------------\n",
        "# 3. ÂÆö‰πâÊçüÂ§±Âíå‰ºòÂåñÂô®\n",
        "# -----------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# -----------------------\n",
        "# 4. Ê®°ÂûãËÆ≠ÁªÉ\n",
        "# -----------------------\n",
        "for epoch in range(10):  # ÂèØÊ†πÊçÆÈúÄË¶ÅÊîπepochÊï∞\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # ÊØè100‰∏™mini-batchÊâìÂç∞‰∏ÄÊ¨°loss\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss/100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "PFAqs1lWEG2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd88be2-d29f-48d2-e54d-be33a32bc1e1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG13_Weights.IMAGENET1K_V1`. You can also use `weights=VGG13_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg13-19584684.pth\" to /root/.cache/torch/hub/checkpoints/vgg13-19584684.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 508M/508M [00:02<00:00, 224MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 100] loss: 1.012\n",
            "[Epoch 1, Batch 200] loss: 0.675\n",
            "[Epoch 1, Batch 300] loss: 0.567\n",
            "[Epoch 1, Batch 400] loss: 0.539\n",
            "[Epoch 1, Batch 500] loss: 0.495\n",
            "[Epoch 1, Batch 600] loss: 0.512\n",
            "[Epoch 1, Batch 700] loss: 0.479\n",
            "[Epoch 2, Batch 100] loss: 0.265\n",
            "[Epoch 2, Batch 200] loss: 0.256\n",
            "[Epoch 2, Batch 300] loss: 0.272\n",
            "[Epoch 2, Batch 400] loss: 0.269\n",
            "[Epoch 2, Batch 500] loss: 0.260\n",
            "[Epoch 2, Batch 600] loss: 0.265\n",
            "[Epoch 2, Batch 700] loss: 0.264\n",
            "[Epoch 3, Batch 100] loss: 0.112\n",
            "[Epoch 3, Batch 200] loss: 0.108\n",
            "[Epoch 3, Batch 300] loss: 0.109\n",
            "[Epoch 3, Batch 400] loss: 0.125\n",
            "[Epoch 3, Batch 500] loss: 0.127\n",
            "[Epoch 3, Batch 600] loss: 0.121\n",
            "[Epoch 3, Batch 700] loss: 0.135\n",
            "[Epoch 4, Batch 100] loss: 0.058\n",
            "[Epoch 4, Batch 200] loss: 0.058\n",
            "[Epoch 4, Batch 300] loss: 0.057\n",
            "[Epoch 4, Batch 400] loss: 0.054\n",
            "[Epoch 4, Batch 500] loss: 0.052\n",
            "[Epoch 4, Batch 600] loss: 0.068\n",
            "[Epoch 4, Batch 700] loss: 0.073\n",
            "[Epoch 5, Batch 100] loss: 0.045\n",
            "[Epoch 5, Batch 200] loss: 0.041\n",
            "[Epoch 5, Batch 300] loss: 0.041\n",
            "[Epoch 5, Batch 400] loss: 0.051\n",
            "[Epoch 5, Batch 500] loss: 0.047\n",
            "[Epoch 5, Batch 600] loss: 0.054\n",
            "[Epoch 5, Batch 700] loss: 0.049\n",
            "[Epoch 6, Batch 100] loss: 0.036\n",
            "[Epoch 6, Batch 200] loss: 0.036\n",
            "[Epoch 6, Batch 300] loss: 0.035\n",
            "[Epoch 6, Batch 400] loss: 0.049\n",
            "[Epoch 6, Batch 500] loss: 0.051\n",
            "[Epoch 6, Batch 600] loss: 0.048\n",
            "[Epoch 6, Batch 700] loss: 0.058\n",
            "[Epoch 7, Batch 100] loss: 0.025\n",
            "[Epoch 7, Batch 200] loss: 0.032\n",
            "[Epoch 7, Batch 300] loss: 0.043\n",
            "[Epoch 7, Batch 400] loss: 0.035\n",
            "[Epoch 7, Batch 500] loss: 0.033\n",
            "[Epoch 7, Batch 600] loss: 0.039\n",
            "[Epoch 7, Batch 700] loss: 0.034\n",
            "[Epoch 8, Batch 100] loss: 0.034\n",
            "[Epoch 8, Batch 200] loss: 0.030\n",
            "[Epoch 8, Batch 300] loss: 0.031\n",
            "[Epoch 8, Batch 400] loss: 0.028\n",
            "[Epoch 8, Batch 500] loss: 0.037\n",
            "[Epoch 8, Batch 600] loss: 0.040\n",
            "[Epoch 8, Batch 700] loss: 0.035\n",
            "[Epoch 9, Batch 100] loss: 0.042\n",
            "[Epoch 9, Batch 200] loss: 0.028\n",
            "[Epoch 9, Batch 300] loss: 0.030\n",
            "[Epoch 9, Batch 400] loss: 0.044\n",
            "[Epoch 9, Batch 500] loss: 0.043\n",
            "[Epoch 9, Batch 600] loss: 0.037\n",
            "[Epoch 9, Batch 700] loss: 0.036\n",
            "[Epoch 10, Batch 100] loss: 0.026\n",
            "[Epoch 10, Batch 200] loss: 0.031\n",
            "[Epoch 10, Batch 300] loss: 0.028\n",
            "[Epoch 10, Batch 400] loss: 0.027\n",
            "[Epoch 10, Batch 500] loss: 0.024\n",
            "[Epoch 10, Batch 600] loss: 0.037\n",
            "[Epoch 10, Batch 700] loss: 0.034\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 5. Ê®°ÂûãÊµãËØï\n",
        "# -----------------------\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrT4AzQsT1xa",
        "outputId": "c2d62629-3a2e-4f2a-f966-0e834d8217ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 86.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# ÂÆö‰πâ‰øùÂ≠òË∑ØÂæÑ\n",
        "save_path = \"/content/drive/MyDrive/Ê®°Âûã/VGG13_CIFAR.pth\"\n",
        "# ‰øùÂ≠òÊ®°ÂûãÂèÇÊï∞\n",
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3OZjsPiUK_i",
        "outputId": "d11cefb1-6e01-49a3-e33a-018f0ac62196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZHt34BueUOhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 2. Âä†ËΩΩÂπ∂‰øÆÊîπÈ¢ÑËÆ≠ÁªÉÊ®°Âûã\n",
        "# -----------------------\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# ÊõøÊç¢ÊúÄÂêé‰∏ÄÂ±ÇÔºö1000 -> 10\n",
        "model.classifier[6] = nn.Linear(4096, 10)\n",
        "\n",
        "# Â∞ÜÊ®°ÂûãÊîæÂà∞ GPUÔºàÂ¶ÇÊúâÔºâ\n",
        "model = model.to(device)\n",
        "\n",
        "# ÂèØÈÄâÔºöÂÜªÁªìÁâπÂæÅÊèêÂèñÈÉ®ÂàÜ\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -----------------------\n",
        "# 3. ÂÆö‰πâÊçüÂ§±Âíå‰ºòÂåñÂô®\n",
        "# -----------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# -----------------------\n",
        "# 4. Ê®°ÂûãËÆ≠ÁªÉ\n",
        "# -----------------------\n",
        "for epoch in range(10):  # ÂèØÊ†πÊçÆÈúÄË¶ÅÊîπepochÊï∞\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # ÊØè100‰∏™mini-batchÊâìÂç∞‰∏ÄÊ¨°loss\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss/100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "IkbEZwGDUQVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 5. Ê®°ÂûãÊµãËØï\n",
        "# -----------------------\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E6Qz6sbUXRb",
        "outputId": "6e15de3b-4617-4b5e-97d3-147ab4ef88de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 86.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# ÂÆö‰πâ‰øùÂ≠òË∑ØÂæÑ\n",
        "save_path = \"/content/drive/MyDrive/Ê®°Âûã/VGG16_CIFAR.pth\"\n",
        "# ‰øùÂ≠òÊ®°ÂûãÂèÇÊï∞\n",
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHOFcffvUVsW",
        "outputId": "a179c869-d129-45e2-8621-cc3bc9539270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Gj0e9F9f4wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 2. Âä†ËΩΩÂπ∂‰øÆÊîπÈ¢ÑËÆ≠ÁªÉÊ®°Âûã\n",
        "# -----------------------\n",
        "model = models.vgg19(pretrained=True)\n",
        "\n",
        "# ÊõøÊç¢ÊúÄÂêé‰∏ÄÂ±ÇÔºö1000 -> 10\n",
        "model.classifier[6] = nn.Linear(4096, 10)\n",
        "\n",
        "# Â∞ÜÊ®°ÂûãÊîæÂà∞ GPUÔºàÂ¶ÇÊúâÔºâ\n",
        "model = model.to(device)\n",
        "\n",
        "# ÂèØÈÄâÔºöÂÜªÁªìÁâπÂæÅÊèêÂèñÈÉ®ÂàÜ\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -----------------------\n",
        "# 3. ÂÆö‰πâÊçüÂ§±Âíå‰ºòÂåñÂô®\n",
        "# -----------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# -----------------------\n",
        "# 4. Ê®°ÂûãËÆ≠ÁªÉ\n",
        "# -----------------------\n",
        "for epoch in range(10):  # ÂèØÊ†πÊçÆÈúÄË¶ÅÊîπepochÊï∞\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # ÊØè100‰∏™mini-batchÊâìÂç∞‰∏ÄÊ¨°loss\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss/100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "-aV8-mvIh3EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 5. Ê®°ÂûãÊµãËØï\n",
        "# -----------------------\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGyWFFfPh4U-",
        "outputId": "a1e9cd61-884d-47da-c4f4-96dd149bebe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 87.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# ÂÆö‰πâ‰øùÂ≠òË∑ØÂæÑ\n",
        "save_path = \"/content/drive/MyDrive/Ê®°Âûã/VGG19_CIFAR.pth\"\n",
        "# ‰øùÂ≠òÊ®°ÂûãÂèÇÊï∞\n",
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Fgfoe3h8q2",
        "outputId": "132f891d-3ab8-4ce6-ae0a-26b3765f9635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "obscbtUDkI8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "meyO6PQXmEtv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}