{"cells":[{"cell_type":"code","source":["from torchvision import models\n","import torch\n","import torch.nn as nn\n","import torch.nn.utils.prune as prune\n","from copy import deepcopy\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"Gp9gJXhvm13O"},"id":"Gp9gJXhvm13O","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchvision\n","import torchvision.transforms as transforms\n","\n","# 数据预处理：resize 和 normalization\n","transform = transforms.Compose([\n","    transforms.Resize(224),  # 因为 VGG 输入是 224x224\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# 加载训练集\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n","\n","# 加载测试集\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4saPUpI6m2YP","executionInfo":{"status":"ok","timestamp":1753395217496,"user_tz":-60,"elapsed":18537,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"07200536-b143-4d23-ff49-327b65b1248c"},"id":"4saPUpI6m2YP","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:13<00:00, 12.5MB/s]\n"]}]},{"cell_type":"code","source":["# 设置设备\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# 2. 挂载 Google Drive（如果还没挂载的话）\n","from google.colab import drive\n","drive.mount('/content/drive')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFogk9Kwm2e3","executionInfo":{"status":"ok","timestamp":1753395242923,"user_tz":-60,"elapsed":23483,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"50d292b1-e92b-4a6a-91a2-a7cdb236d289"},"id":"JFogk9Kwm2e3","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","cuda\n"]}]},{"cell_type":"code","source":["basemodel = models.vgg16()  # 或者你自定义的 VGG19-CIFAR 版本\n","\n","# 如果你之前做了修改（比如分类数不同），需要一致设置：\n","basemodel.classifier[6] = torch.nn.Linear(4096, 10)  # CIFAR-10 分类任务\n","\n","# 4. 加载参数\n","save_path = \"/content/drive/MyDrive/模型/VGG16_CIFAR.pth\"\n","basemodel.load_state_dict(torch.load(save_path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"LNF9a3cdm2kO","executionInfo":{"status":"ok","timestamp":1753371039779,"user_tz":-60,"elapsed":10464,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"bbe2778e-f1a9-48fe-d3ca-2dd7abc9749f"},"id":"LNF9a3cdm2kO","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["print(basemodel)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"K7ocxCAMm2ow","executionInfo":{"status":"ok","timestamp":1753365013481,"user_tz":-60,"elapsed":49,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"e9ec272d-7c02-414a-f930-c8779c905a06"},"id":"K7ocxCAMm2ow","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): ReLU(inplace=True)\n","    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (14): ReLU(inplace=True)\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace=True)\n","    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (19): ReLU(inplace=True)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["# 测试函数\n","def test_accuracy(model, dataloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for x, y in dataloader:\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            pred = output.argmax(dim=1)\n","            correct += (pred == y).sum().item()\n","            total += y.size(0)\n","    return 100 * correct / total"],"metadata":{"id":"lETdFrKwytdg"},"id":"lETdFrKwytdg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 剪枝率列表\n","prune_rates = [0.1, 0.3, 0.5, 0.7, 0.9]\n","\n","# 找到所有Conv层\n","conv_layers = [(name, m) for name, m in basemodel.features.named_modules() if isinstance(m, nn.Conv2d)]\n","print(\"-----VGG16-----\")\n","\n","# 对每个Conv层进行多种剪枝测试\n","for i, (layer_name, layer) in enumerate(conv_layers):\n","    for rate in prune_rates:\n","        # 深拷贝模型\n","        model = deepcopy(basemodel)\n","        model.to(device)\n","        model.eval()\n","        # 获取当前层对象\n","        target_layer = dict(model.features.named_modules())[layer_name]\n","        # 执行剪枝\n","        prune.l1_unstructured(target_layer, name='weight', amount=rate)\n","        # 评估剪枝后模型的准确率\n","        acc = test_accuracy(model, testloader)\n","        print(f\"[Layer {i}] Pruned {layer_name} with {int(rate*100)}% -> Accuracy: {acc:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"_eGThJo8m2tL","executionInfo":{"status":"ok","timestamp":1753372839026,"user_tz":-60,"elapsed":1767621,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"7e1ae2ac-16e8-446d-e4ff-7ae53e798127"},"id":"_eGThJo8m2tL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-----VGG16-----\n","[Layer 0] Pruned 0 with 10% -> Accuracy: 86.70%\n","[Layer 0] Pruned 0 with 30% -> Accuracy: 85.67%\n","[Layer 0] Pruned 0 with 50% -> Accuracy: 81.76%\n","[Layer 0] Pruned 0 with 70% -> Accuracy: 63.25%\n","[Layer 0] Pruned 0 with 90% -> Accuracy: 20.80%\n","[Layer 1] Pruned 2 with 10% -> Accuracy: 86.54%\n","[Layer 1] Pruned 2 with 30% -> Accuracy: 86.48%\n","[Layer 1] Pruned 2 with 50% -> Accuracy: 86.46%\n","[Layer 1] Pruned 2 with 70% -> Accuracy: 84.84%\n","[Layer 1] Pruned 2 with 90% -> Accuracy: 66.55%\n","[Layer 2] Pruned 5 with 10% -> Accuracy: 86.58%\n","[Layer 2] Pruned 5 with 30% -> Accuracy: 86.58%\n","[Layer 2] Pruned 5 with 50% -> Accuracy: 86.39%\n","[Layer 2] Pruned 5 with 70% -> Accuracy: 85.58%\n","[Layer 2] Pruned 5 with 90% -> Accuracy: 76.48%\n","[Layer 3] Pruned 7 with 10% -> Accuracy: 86.57%\n","[Layer 3] Pruned 7 with 30% -> Accuracy: 86.56%\n","[Layer 3] Pruned 7 with 50% -> Accuracy: 85.57%\n","[Layer 3] Pruned 7 with 70% -> Accuracy: 83.82%\n","[Layer 3] Pruned 7 with 90% -> Accuracy: 62.62%\n","[Layer 4] Pruned 10 with 10% -> Accuracy: 86.59%\n","[Layer 4] Pruned 10 with 30% -> Accuracy: 86.43%\n","[Layer 4] Pruned 10 with 50% -> Accuracy: 86.71%\n","[Layer 4] Pruned 10 with 70% -> Accuracy: 84.04%\n","[Layer 4] Pruned 10 with 90% -> Accuracy: 48.71%\n","[Layer 5] Pruned 12 with 10% -> Accuracy: 86.59%\n","[Layer 5] Pruned 12 with 30% -> Accuracy: 86.59%\n","[Layer 5] Pruned 12 with 50% -> Accuracy: 86.18%\n","[Layer 5] Pruned 12 with 70% -> Accuracy: 85.28%\n","[Layer 5] Pruned 12 with 90% -> Accuracy: 74.54%\n","[Layer 6] Pruned 14 with 10% -> Accuracy: 86.56%\n","[Layer 6] Pruned 14 with 30% -> Accuracy: 86.44%\n","[Layer 6] Pruned 14 with 50% -> Accuracy: 85.94%\n","[Layer 6] Pruned 14 with 70% -> Accuracy: 83.78%\n","[Layer 6] Pruned 14 with 90% -> Accuracy: 57.76%\n","[Layer 7] Pruned 17 with 10% -> Accuracy: 86.57%\n","[Layer 7] Pruned 17 with 30% -> Accuracy: 86.58%\n","[Layer 7] Pruned 17 with 50% -> Accuracy: 86.47%\n","[Layer 7] Pruned 17 with 70% -> Accuracy: 84.72%\n","[Layer 7] Pruned 17 with 90% -> Accuracy: 65.53%\n","[Layer 8] Pruned 19 with 10% -> Accuracy: 86.52%\n","[Layer 8] Pruned 19 with 30% -> Accuracy: 86.57%\n","[Layer 8] Pruned 19 with 50% -> Accuracy: 86.19%\n","[Layer 8] Pruned 19 with 70% -> Accuracy: 83.62%\n","[Layer 8] Pruned 19 with 90% -> Accuracy: 40.79%\n","[Layer 9] Pruned 21 with 10% -> Accuracy: 86.57%\n","[Layer 9] Pruned 21 with 30% -> Accuracy: 86.62%\n","[Layer 9] Pruned 21 with 50% -> Accuracy: 86.57%\n","[Layer 9] Pruned 21 with 70% -> Accuracy: 84.58%\n","[Layer 9] Pruned 21 with 90% -> Accuracy: 40.25%\n","[Layer 10] Pruned 24 with 10% -> Accuracy: 86.55%\n","[Layer 10] Pruned 24 with 30% -> Accuracy: 86.58%\n","[Layer 10] Pruned 24 with 50% -> Accuracy: 86.48%\n","[Layer 10] Pruned 24 with 70% -> Accuracy: 84.51%\n","[Layer 10] Pruned 24 with 90% -> Accuracy: 54.65%\n","[Layer 11] Pruned 26 with 10% -> Accuracy: 86.57%\n","[Layer 11] Pruned 26 with 30% -> Accuracy: 86.49%\n","[Layer 11] Pruned 26 with 50% -> Accuracy: 86.30%\n","[Layer 11] Pruned 26 with 70% -> Accuracy: 83.92%\n","[Layer 11] Pruned 26 with 90% -> Accuracy: 65.91%\n","[Layer 12] Pruned 28 with 10% -> Accuracy: 86.61%\n","[Layer 12] Pruned 28 with 30% -> Accuracy: 86.65%\n","[Layer 12] Pruned 28 with 50% -> Accuracy: 86.25%\n","[Layer 12] Pruned 28 with 70% -> Accuracy: 84.34%\n","[Layer 12] Pruned 28 with 90% -> Accuracy: 70.41%\n"]}]},{"cell_type":"code","source":["model = models.vgg11()\n","model.classifier[6] = nn.Linear(4096,10)\n","\n","save_path = \"/content/drive/MyDrive/模型/VGG11_CIFAR.pth\"\n","model.load_state_dict(torch.load(save_path))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8BoFtjXfRBR","executionInfo":{"status":"ok","timestamp":1753397047698,"user_tz":-60,"elapsed":2566,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"140fbfc6-a896-417e-9bb0-baf70d8c6c69"},"id":"N8BoFtjXfRBR","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["model = model.to(device)"],"metadata":{"id":"84WF64f9f1v_"},"id":"84WF64f9f1v_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = test_accuracy(model,testloader)\n","acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4f5-td7gJNf","executionInfo":{"status":"ok","timestamp":1753395318559,"user_tz":-60,"elapsed":16395,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"bb58c605-429b-42a4-a0ad-41be35a68eb0"},"id":"s4f5-td7gJNf","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["86.06"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def count_conv_params(model):\n","    total = 0\n","    for module in model.features.modules():\n","        if isinstance(module, torch.nn.Conv2d):\n","            total += sum(p.numel() for p in module.parameters())\n","    return total\n","\n","print(f\"Total Conv2d parameters (before pruning): {count_conv_params(model)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e64vO4wThYBG","executionInfo":{"status":"ok","timestamp":1753395694993,"user_tz":-60,"elapsed":6,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"4e47b5f6-06ff-482d-f686-1e7ecab5e91f"},"id":"e64vO4wThYBG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Conv2d parameters (before pruning): 9220480\n"]}]},{"cell_type":"code","source":["# 收集所有 Conv2d 层\n","parameters_to_prune = []\n","for name, module in model.features.named_modules():\n","    if isinstance(module, torch.nn.Conv2d):\n","        parameters_to_prune.append((module, 'weight'))\n","\n","# 执行全局剪枝（50%）\n","prune.global_unstructured(\n","    parameters_to_prune,\n","    pruning_method=prune.L1Unstructured,\n","    amount=0.6  # 剪枝 50%---->84%---->稀疏度3.58%\n",")\n","#128807306卷积：9220480\n","global_acc = test_accuracy(model,testloader)\n","\n","print(f\"剪枝之后，准确率为:{global_acc}，未剪枝的时候参数数量为{count_conv_params(model)}\")"],"metadata":{"id":"6fw_CftHC4Q4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753397082405,"user_tz":-60,"elapsed":15586,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"a6cf93e6-e7c6-4040-e24c-f405e3d37511"},"id":"6fw_CftHC4Q4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["剪枝之后，准确率为:79.97，未剪枝的时候参数数量为9220480\n"]}]},{"cell_type":"code","source":["def count_zero_weights_pruned(model):\n","    total, zeros = 0, 0\n","    for name, module in model.named_modules():\n","        if hasattr(module, \"weight\"):\n","            w = module.weight.detach()  # 这是带 mask 的权重\n","            total += w.numel()\n","            zeros += torch.sum(w == 0).item()\n","    return total, zeros, 100 * zeros / total\n","\n","total, zeros, zero_ratio = count_zero_weights_pruned(model)\n","print(f\"Total weights: {total}\")\n","print(f\"Zero weights: {zeros}\")\n","print(f\"Sparsity: {zero_ratio:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJM0rO1Qi6Qu","executionInfo":{"status":"ok","timestamp":1753397082422,"user_tz":-60,"elapsed":4,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"4382ab1b-8f3c-4e10-fdf7-de38db4e298f"},"id":"FJM0rO1Qi6Qu","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total weights: 128796352\n","Zero weights: 5530637\n","Sparsity: 4.29%\n"]}]},{"cell_type":"code","source":["4608864/128796352"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EZ8dAFqgjHt4","executionInfo":{"status":"ok","timestamp":1753396800718,"user_tz":-60,"elapsed":16,"user":{"displayName":"ZHE YUAN","userId":"10416376004896786598"}},"outputId":"67ab768f-2871-4936-b6eb-98ee0521f459"},"id":"EZ8dAFqgjHt4","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.03578411910300068"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"XoUR2uUul-sb"},"id":"XoUR2uUul-sb","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"},"colab":{"provenance":[],"gpuType":"L4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}